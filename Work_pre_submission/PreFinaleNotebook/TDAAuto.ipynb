{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-15T17:23:24.050091Z","iopub.execute_input":"2023-01-15T17:23:24.050505Z","iopub.status.idle":"2023-01-15T17:23:24.082240Z","shell.execute_reply.started":"2023-01-15T17:23:24.050420Z","shell.execute_reply":"2023-01-15T17:23:24.081210Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/the-data-alchemist-techweek-23/train.csv\n/kaggle/input/the-data-alchemist-techweek-23/test.csv\n/kaggle/input/the-data-alchemist-techweek-23/sample_solution.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install mljar-supervised","metadata":{"execution":{"iopub.status.busy":"2023-01-15T17:23:24.084512Z","iopub.execute_input":"2023-01-15T17:23:24.085185Z","iopub.status.idle":"2023-01-15T17:23:42.034609Z","shell.execute_reply.started":"2023-01-15T17:23:24.085155Z","shell.execute_reply":"2023-01-15T17:23:42.033256Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting mljar-supervised\n  Downloading mljar-supervised-0.11.5.tar.gz (112 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.7/112.7 kB\u001b[0m \u001b[31m285.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.7/site-packages (from mljar-supervised) (1.21.6)\nRequirement already satisfied: pandas>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from mljar-supervised) (1.3.5)\nRequirement already satisfied: scipy>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from mljar-supervised) (1.7.3)\nRequirement already satisfied: scikit-learn>=1.0 in /opt/conda/lib/python3.7/site-packages (from mljar-supervised) (1.0.2)\nRequirement already satisfied: xgboost>=1.3.3 in /opt/conda/lib/python3.7/site-packages (from mljar-supervised) (1.6.2)\nRequirement already satisfied: lightgbm>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from mljar-supervised) (3.3.2)\nRequirement already satisfied: catboost>=0.24.4 in /opt/conda/lib/python3.7/site-packages (from mljar-supervised) (1.1.1)\nRequirement already satisfied: joblib>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from mljar-supervised) (1.0.1)\nRequirement already satisfied: tabulate>=0.8.7 in /opt/conda/lib/python3.7/site-packages (from mljar-supervised) (0.9.0)\nRequirement already satisfied: matplotlib>=3.2.2 in /opt/conda/lib/python3.7/site-packages (from mljar-supervised) (3.5.3)\nCollecting dtreeviz>=2.0.0\n  Downloading dtreeviz-2.0.0-py3-none-any.whl (78 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.0/79.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: shap>=0.36.0 in /opt/conda/lib/python3.7/site-packages (from mljar-supervised) (0.41.0)\nRequirement already satisfied: seaborn>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from mljar-supervised) (0.11.2)\nRequirement already satisfied: wordcloud>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from mljar-supervised) (1.8.2.2)\nRequirement already satisfied: category_encoders>=2.2.2 in /opt/conda/lib/python3.7/site-packages (from mljar-supervised) (2.5.1.post0)\nRequirement already satisfied: optuna>=2.7.0 in /opt/conda/lib/python3.7/site-packages (from mljar-supervised) (3.0.5)\nRequirement already satisfied: scikit-plot==0.3.7 in /opt/conda/lib/python3.7/site-packages (from mljar-supervised) (0.3.7)\nRequirement already satisfied: markdown in /opt/conda/lib/python3.7/site-packages (from mljar-supervised) (3.3.7)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from mljar-supervised) (4.1.1)\nRequirement already satisfied: graphviz in /opt/conda/lib/python3.7/site-packages (from catboost>=0.24.4->mljar-supervised) (0.8.4)\nRequirement already satisfied: plotly in /opt/conda/lib/python3.7/site-packages (from catboost>=0.24.4->mljar-supervised) (5.11.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from catboost>=0.24.4->mljar-supervised) (1.15.0)\nRequirement already satisfied: statsmodels>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from category_encoders>=2.2.2->mljar-supervised) (0.13.2)\nRequirement already satisfied: patsy>=0.5.1 in /opt/conda/lib/python3.7/site-packages (from category_encoders>=2.2.2->mljar-supervised) (0.5.2)\nRequirement already satisfied: pytest in /opt/conda/lib/python3.7/site-packages (from dtreeviz>=2.0.0->mljar-supervised) (7.2.0)\nCollecting graphviz\n  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting colour\n  Downloading colour-0.1.5-py2.py3-none-any.whl (23 kB)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from lightgbm>=3.0.0->mljar-supervised) (0.37.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.2->mljar-supervised) (4.33.3)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.2->mljar-supervised) (0.11.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.2->mljar-supervised) (22.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.2->mljar-supervised) (1.4.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.2->mljar-supervised) (9.1.1)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.2->mljar-supervised) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.2->mljar-supervised) (2.8.2)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from optuna>=2.7.0->mljar-supervised) (6.0)\nRequirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from optuna>=2.7.0->mljar-supervised) (1.9.1)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from optuna>=2.7.0->mljar-supervised) (1.4.39)\nRequirement already satisfied: importlib-metadata<5.0.0 in /opt/conda/lib/python3.7/site-packages (from optuna>=2.7.0->mljar-supervised) (4.13.0)\nRequirement already satisfied: cmaes>=0.8.2 in /opt/conda/lib/python3.7/site-packages (from optuna>=2.7.0->mljar-supervised) (0.9.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from optuna>=2.7.0->mljar-supervised) (4.64.0)\nRequirement already satisfied: cliff in /opt/conda/lib/python3.7/site-packages (from optuna>=2.7.0->mljar-supervised) (3.10.1)\nRequirement already satisfied: colorlog in /opt/conda/lib/python3.7/site-packages (from optuna>=2.7.0->mljar-supervised) (6.7.0)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.2.0->mljar-supervised) (2022.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=1.0->mljar-supervised) (3.1.0)\nRequirement already satisfied: slicer==0.0.7 in /opt/conda/lib/python3.7/site-packages (from shap>=0.36.0->mljar-supervised) (0.0.7)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from shap>=0.36.0->mljar-supervised) (2.1.0)\nRequirement already satisfied: numba in /opt/conda/lib/python3.7/site-packages (from shap>=0.36.0->mljar-supervised) (0.55.2)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.7/site-packages (from alembic>=1.5.0->optuna>=2.7.0->mljar-supervised) (1.2.4)\nRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.7/site-packages (from alembic>=1.5.0->optuna>=2.7.0->mljar-supervised) (5.10.2)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0.0->optuna>=2.7.0->mljar-supervised) (3.8.0)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.7/site-packages (from sqlalchemy>=1.3.0->optuna>=2.7.0->mljar-supervised) (1.1.2)\nRequirement already satisfied: PrettyTable>=0.7.2 in /opt/conda/lib/python3.7/site-packages (from cliff->optuna>=2.7.0->mljar-supervised) (3.3.0)\nRequirement already satisfied: pbr!=2.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from cliff->optuna>=2.7.0->mljar-supervised) (5.11.0)\nRequirement already satisfied: autopage>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from cliff->optuna>=2.7.0->mljar-supervised) (0.5.1)\nRequirement already satisfied: stevedore>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from cliff->optuna>=2.7.0->mljar-supervised) (3.5.2)\nRequirement already satisfied: cmd2>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from cliff->optuna>=2.7.0->mljar-supervised) (2.4.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba->shap>=0.36.0->mljar-supervised) (59.8.0)\nRequirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba->shap>=0.36.0->mljar-supervised) (0.38.1)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from plotly->catboost>=0.24.4->mljar-supervised) (8.0.1)\nRequirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.7/site-packages (from pytest->dtreeviz>=2.0.0->mljar-supervised) (21.4.0)\nRequirement already satisfied: iniconfig in /opt/conda/lib/python3.7/site-packages (from pytest->dtreeviz>=2.0.0->mljar-supervised) (1.1.1)\nRequirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest->dtreeviz>=2.0.0->mljar-supervised) (1.0.0)\nRequirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.7/site-packages (from pytest->dtreeviz>=2.0.0->mljar-supervised) (1.1.0)\nRequirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from pytest->dtreeviz>=2.0.0->mljar-supervised) (2.0.1)\nRequirement already satisfied: wcwidth>=0.1.7 in /opt/conda/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna>=2.7.0->mljar-supervised) (0.2.5)\nRequirement already satisfied: pyperclip>=1.6 in /opt/conda/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna>=2.7.0->mljar-supervised) (1.8.2)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.7/site-packages (from Mako->alembic>=1.5.0->optuna>=2.7.0->mljar-supervised) (2.1.1)\nBuilding wheels for collected packages: mljar-supervised\n  Building wheel for mljar-supervised (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for mljar-supervised: filename=mljar_supervised-0.11.5-py3-none-any.whl size=147064 sha256=bbe2added11a7f47f86541261b58423225d233b80d952743f6bd8ccf5898993e\n  Stored in directory: /root/.cache/pip/wheels/f7/10/83/872e9d45883cc0a26310ff67e6b2c45f4c2360a8366ab959aa\nSuccessfully built mljar-supervised\nInstalling collected packages: colour, graphviz, dtreeviz, mljar-supervised\n  Attempting uninstall: graphviz\n    Found existing installation: graphviz 0.8.4\n    Uninstalling graphviz-0.8.4:\n      Successfully uninstalled graphviz-0.8.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nmxnet 1.9.1 requires graphviz<0.9.0,>=0.8.1, but you have graphviz 0.20.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed colour-0.1.5 dtreeviz-2.0.0 graphviz-0.20.1 mljar-supervised-0.11.5\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom supervised.automl import AutoML\n","metadata":{"execution":{"iopub.status.busy":"2023-01-15T17:23:42.036320Z","iopub.execute_input":"2023-01-15T17:23:42.036764Z","iopub.status.idle":"2023-01-15T17:23:48.387361Z","shell.execute_reply.started":"2023-01-15T17:23:42.036718Z","shell.execute_reply":"2023-01-15T17:23:48.386076Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}}]},{"cell_type":"code","source":"import supervised\nsupervised.__version__","metadata":{"execution":{"iopub.status.busy":"2023-01-15T17:23:48.389166Z","iopub.execute_input":"2023-01-15T17:23:48.389553Z","iopub.status.idle":"2023-01-15T17:23:48.396177Z","shell.execute_reply.started":"2023-01-15T17:23:48.389515Z","shell.execute_reply":"2023-01-15T17:23:48.395387Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'0.11.5'"},"metadata":{}}]},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/the-data-alchemist-techweek-23/train.csv')\ndf_test = pd.read_csv('/kaggle/input/the-data-alchemist-techweek-23/test.csv')\n","metadata":{"execution":{"iopub.status.busy":"2023-01-15T17:23:48.399134Z","iopub.execute_input":"2023-01-15T17:23:48.399607Z","iopub.status.idle":"2023-01-15T17:23:48.461324Z","shell.execute_reply.started":"2023-01-15T17:23:48.399552Z","shell.execute_reply":"2023-01-15T17:23:48.460353Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(f\"The train data set contains {df_train.shape[0]} rows and {df_train.shape[1]} cols\")\nprint(f\"The test data set contains {df_test.shape[0]} rows and {df_test.shape[1]} cols\")","metadata":{"execution":{"iopub.status.busy":"2023-01-15T17:23:48.462733Z","iopub.execute_input":"2023-01-15T17:23:48.463110Z","iopub.status.idle":"2023-01-15T17:23:48.469125Z","shell.execute_reply.started":"2023-01-15T17:23:48.463064Z","shell.execute_reply":"2023-01-15T17:23:48.467781Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"The train data set contains 266 rows and 51 cols\nThe test data set contains 114 rows and 50 cols\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train,y_train = df_train.drop(['result'],axis=1),df_train['result']","metadata":{"execution":{"iopub.status.busy":"2023-01-15T17:23:48.470343Z","iopub.execute_input":"2023-01-15T17:23:48.471281Z","iopub.status.idle":"2023-01-15T17:23:48.489718Z","shell.execute_reply.started":"2023-01-15T17:23:48.471248Z","shell.execute_reply":"2023-01-15T17:23:48.488743Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"a = AutoML(mode='Compete')\na.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2023-01-15T17:23:48.491651Z","iopub.execute_input":"2023-01-15T17:23:48.492400Z","iopub.status.idle":"2023-01-15T18:15:12.386981Z","shell.execute_reply.started":"2023-01-15T17:23:48.492349Z","shell.execute_reply":"2023-01-15T18:15:12.385875Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"AutoML directory: AutoML_1\nThe task is multiclass_classification with evaluation metric logloss\nAutoML will use algorithms: ['Decision Tree', 'Linear', 'Random Forest', 'Extra Trees', 'LightGBM', 'Xgboost', 'CatBoost', 'Neural Network', 'Nearest Neighbors']\nAutoML will stack models\nAutoML will ensemble available models\nAutoML steps: ['adjust_validation', 'simple_algorithms', 'default_algorithms', 'not_so_random', 'mix_encoding', 'golden_features', 'kmeans_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'boost_on_errors', 'ensemble', 'stack', 'ensemble_stacked']\n* Step adjust_validation will try to check up to 1 model\n1_DecisionTree logloss 1.277173 trained in 0.43 seconds\nAdjust validation. Remove: 1_DecisionTree\n*** Disable stacking for small dataset (nrows < 500)\nValidation strategy: 10-fold CV Shuffle,Stratify\n* Step simple_algorithms will try to check up to 4 models\n1_DecisionTree logloss 1.379774 trained in 2.5 seconds\n2_DecisionTree logloss 1.937565 trained in 2.48 seconds\n3_DecisionTree logloss 1.903756 trained in 2.61 seconds\n4_Linear logloss 1.121908 trained in 5.33 seconds\n* Step default_algorithms will try to check up to 7 models\n5_Default_LightGBM logloss 0.969525 trained in 4.01 seconds\n6_Default_Xgboost logloss 1.00103 trained in 11.13 seconds\n7_Default_CatBoost logloss 0.921013 trained in 7.09 seconds\n8_Default_NeuralNetwork logloss 1.170157 trained in 8.82 seconds\n9_Default_RandomForest logloss 0.955034 trained in 12.45 seconds\n10_Default_ExtraTrees logloss 0.94094 trained in 11.75 seconds\n11_Default_NearestNeighbors logloss 2.648064 trained in 6.2 seconds\n* Step not_so_random will try to check up to 61 models\n21_LightGBM logloss 0.93291 trained in 4.48 seconds\n12_Xgboost logloss 0.986137 trained in 11.37 seconds\n30_CatBoost logloss 0.922442 trained in 5.94 seconds\n39_RandomForest logloss 0.952006 trained in 14.46 seconds\n48_ExtraTrees logloss 0.955412 trained in 12.07 seconds\n57_NeuralNetwork logloss 1.149682 trained in 7.97 seconds\n66_NearestNeighbors logloss 1.889116 trained in 7.4 seconds\n22_LightGBM logloss 0.958731 trained in 5.86 seconds\n13_Xgboost logloss 1.009105 trained in 12.88 seconds\n31_CatBoost logloss 0.92164 trained in 8.44 seconds\n40_RandomForest logloss 0.971951 trained in 16.55 seconds\n49_ExtraTrees logloss 0.972923 trained in 15.27 seconds\n58_NeuralNetwork logloss 1.07789 trained in 10.04 seconds\n67_NearestNeighbors logloss 1.896379 trained in 8.44 seconds\n23_LightGBM logloss 0.956665 trained in 7.01 seconds\n14_Xgboost logloss 0.939536 trained in 14.35 seconds\n32_CatBoost logloss 0.917835 trained in 13.55 seconds\n41_RandomForest logloss 0.929898 trained in 15.88 seconds\n50_ExtraTrees logloss 0.952781 trained in 14.62 seconds\n59_NeuralNetwork logloss 2.163023 trained in 10.8 seconds\n68_NearestNeighbors logloss 1.896379 trained in 9.58 seconds\n24_LightGBM logloss 0.980504 trained in 8.54 seconds\n15_Xgboost logloss 1.038297 trained in 16.15 seconds\n33_CatBoost logloss 0.929781 trained in 14.47 seconds\n42_RandomForest logloss 0.952117 trained in 18.33 seconds\n51_ExtraTrees logloss 0.933846 trained in 16.4 seconds\n60_NeuralNetwork logloss 1.228387 trained in 12.71 seconds\n69_NearestNeighbors logloss 1.889116 trained in 10.85 seconds\n25_LightGBM logloss 0.933694 trained in 8.92 seconds\n16_Xgboost logloss 0.983076 trained in 20.15 seconds\n34_CatBoost logloss 0.917486 trained in 11.77 seconds\n43_RandomForest logloss 0.940198 trained in 17.01 seconds\n52_ExtraTrees logloss 0.933792 trained in 16.0 seconds\n61_NeuralNetwork logloss 1.096743 trained in 13.72 seconds\n70_NearestNeighbors logloss 3.808543 trained in 11.85 seconds\n26_LightGBM logloss 0.950813 trained in 10.21 seconds\n17_Xgboost logloss 0.950855 trained in 18.85 seconds\n35_CatBoost logloss 0.910403 trained in 11.73 seconds\n44_RandomForest logloss 0.936311 trained in 21.81 seconds\n53_ExtraTrees logloss 0.965617 trained in 19.26 seconds\n62_NeuralNetwork logloss 1.10381 trained in 15.1 seconds\n71_NearestNeighbors logloss 1.889116 trained in 13.0 seconds\n27_LightGBM logloss 0.943895 trained in 11.3 seconds\n18_Xgboost logloss 0.939822 trained in 22.57 seconds\n36_CatBoost logloss 0.932696 trained in 14.89 seconds\n45_RandomForest logloss 0.945704 trained in 20.65 seconds\n54_ExtraTrees logloss 0.957632 trained in 19.48 seconds\n63_NeuralNetwork logloss 0.98801 trained in 13.15 seconds\n72_NearestNeighbors logloss 3.807758 trained in 14.21 seconds\n28_LightGBM logloss 0.977665 trained in 13.4 seconds\n19_Xgboost logloss 0.962189 trained in 34.42 seconds\n37_CatBoost logloss 0.924881 trained in 14.77 seconds\n46_RandomForest logloss 0.959535 trained in 22.47 seconds\n55_ExtraTrees logloss 0.963014 trained in 23.34 seconds\n64_NeuralNetwork logloss 1.478151 trained in 15.94 seconds\n29_LightGBM logloss 0.947256 trained in 13.49 seconds\n20_Xgboost logloss 0.983331 trained in 22.29 seconds\n38_CatBoost logloss 0.924505 trained in 21.75 seconds\n47_RandomForest logloss 0.945062 trained in 23.09 seconds\n56_ExtraTrees logloss 0.945761 trained in 23.59 seconds\n65_NeuralNetwork logloss 1.269952 trained in 15.25 seconds\n* Step mix_encoding will try to check up to 1 model\n14_Xgboost_categorical_mix logloss 0.933575 trained in 23.09 seconds\n* Step golden_features will try to check up to 3 models\nNone 10\nAdd Golden Feature: Ladbrokes draw odds_diff_Betbrain Asian bookies\nAdd Golden Feature: Betbrain 1X2 bookies_ratio_Betbrain max >2.5\nAdd Golden Feature: Betbrain max >2.5_ratio_Betbrain 1X2 bookies\nAdd Golden Feature: Interwetten draw odds_sum_Bet&Win draw odds\nAdd Golden Feature: Stan James draw odds_sum_Bet365 draw odds\nAdd Golden Feature: VC Bet away odds_diff_Betbrain average <2.5\nAdd Golden Feature: Sportingbet draw odds_sum_Bet&Win draw odds\nAdd Golden Feature: Ladbrokes away odds_diff_VC Bet away odds\nAdd Golden Feature: Sportingbet draw odds_multiply_gamebookers draw odds\nAdd Golden Feature: Stan James draw odds_multiply_Bet365 draw odds\nCreated 10 Golden Features in 11.02 seconds.\n35_CatBoost_GoldenFeatures logloss 0.913284 trained in 27.08 seconds\n34_CatBoost_GoldenFeatures logloss 0.910104 trained in 17.69 seconds\n32_CatBoost_GoldenFeatures logloss 0.913449 trained in 22.87 seconds\n* Step kmeans_features will try to check up to 3 models\n35_CatBoost_KMeansFeatures logloss 0.911265 trained in 19.32 seconds\n34_CatBoost_KMeansFeatures logloss 0.915 trained in 23.64 seconds\n32_CatBoost_KMeansFeatures logloss 0.917155 trained in 36.56 seconds\n* Step insert_random_feature will try to check up to 1 model\n34_CatBoost_GoldenFeatures_RandomFeature logloss 0.91402 trained in 32.47 seconds\nDrop features ['Betbrain average draw odds.1', 'Bet365 away odds', 'HomeTeam', 'Bet&Win home odds', 'Interwetten away odds', 'Betbrain 1X2 bookies', 'Betbrain max >2.5', 'AwayTeam', 'Ladbrokes home odds', 'Sportingbet away odds', 'id', 'Will Hill home odds', 'Betbrain Asian home handicap', 'Ladbrokes away odds', 'Ladbrokes draw odds_diff_Betbrain Asian bookies', 'Betbrain max <2.5', 'Betbrain average <2.5', 'Betbrain max home odds', 'VC Bet away odds_diff_Betbrain average <2.5', 'Bet&Win away odds', 'Betbrain average home odds', 'gamebookers draw odds', 'gamebookers home odds', 'Bet365 home odds', 'Interwetten draw odds', 'Stan James draw odds_sum_Bet365 draw odds', 'random_feature', 'VC Bet home odds', 'Betbrain max draw odds', 'Stan James draw odds_multiply_Bet365 draw odds', 'Betbrain max away odds', 'Sportingbet draw odds_multiply_gamebookers draw odds', 'Sportingbet home odds', 'Sportingbet draw odds', 'VC Bet away odds', 'Betbrain average draw odds', 'Stan James draw odds', 'Betbrain average >2.5', 'VC Bet draw odds', 'Bet365 draw odds', 'Betbrain average Asian home odds', 'Betbrain Asian bookies', 'Interwetten draw odds_sum_Bet&Win draw odds', 'Stan James home odds', 'Date', 'Ladbrokes away odds_diff_VC Bet away odds', 'gamebookers away odds', 'Interwetten home odds', 'Betbrain 1X2 bookies_ratio_Betbrain max >2.5', 'Betbrain max Asian away odds', 'Betbrain max >2.5_ratio_Betbrain 1X2 bookies', 'Stan James away odds', 'Will Hill draw odds', 'Ladbrokes draw odds', 'Sportingbet draw odds_sum_Bet&Win draw odds', 'Betbrain max Asian home odds', 'Bet&Win draw odds']\n* Step features_selection will try to check up to 6 models\n34_CatBoost_GoldenFeatures_SelectedFeatures logloss 0.928722 trained in 15.75 seconds\n41_RandomForest_SelectedFeatures logloss 0.938581 trained in 24.4 seconds\n21_LightGBM_SelectedFeatures logloss 0.920312 trained in 16.51 seconds\n14_Xgboost_categorical_mix_SelectedFeatures logloss 0.936136 trained in 27.68 seconds\n52_ExtraTrees_SelectedFeatures logloss 0.944242 trained in 21.84 seconds\n63_NeuralNetwork_SelectedFeatures logloss 0.966751 trained in 17.77 seconds\n* Step hill_climbing_1 will try to check up to 25 models\n73_CatBoost_GoldenFeatures logloss 0.927397 trained in 20.32 seconds\n74_CatBoost logloss 0.917935 trained in 18.44 seconds\n75_CatBoost logloss 0.923799 trained in 21.74 seconds\n76_LightGBM_SelectedFeatures logloss 0.920312 trained in 17.81 seconds\n77_RandomForest logloss 0.946322 trained in 26.28 seconds\n78_LightGBM logloss 0.93291 trained in 18.13 seconds\n79_Xgboost logloss 0.935656 trained in 28.86 seconds\n80_Xgboost logloss 0.92657 trained in 28.72 seconds\n81_LightGBM logloss 0.933694 trained in 18.54 seconds\n82_ExtraTrees logloss 0.943922 trained in 25.84 seconds\n83_ExtraTrees logloss 0.94779 trained in 26.18 seconds\n84_Xgboost_SelectedFeatures logloss 0.936557 trained in 36.36 seconds\n85_Xgboost_SelectedFeatures logloss 0.925216 trained in 40.09 seconds\n86_RandomForest logloss 0.96326 trained in 30.17 seconds\n87_RandomForest_SelectedFeatures logloss 0.950668 trained in 26.83 seconds\n88_Xgboost logloss 0.942819 trained in 28.57 seconds\n89_Xgboost logloss 0.927383 trained in 27.66 seconds\n90_ExtraTrees logloss 0.970944 trained in 29.51 seconds\n91_NeuralNetwork_SelectedFeatures logloss 0.968111 trained in 20.69 seconds\n92_NeuralNetwork_SelectedFeatures logloss 0.944532 trained in 21.34 seconds\n93_NeuralNetwork logloss 1.005313 trained in 21.41 seconds\n94_NeuralNetwork logloss 1.113018 trained in 21.98 seconds\n95_NeuralNetwork logloss 1.271015 trained in 24.36 seconds\n96_NeuralNetwork logloss 1.215189 trained in 24.33 seconds\n97_DecisionTree logloss 1.099868 trained in 20.48 seconds\n* Step hill_climbing_2 will try to check up to 28 models\n98_CatBoost_GoldenFeatures logloss 0.92489 trained in 24.7 seconds\n99_CatBoost logloss 0.909827 trained in 22.55 seconds\n100_CatBoost logloss 0.932696 trained in 25.42 seconds\n101_LightGBM_SelectedFeatures logloss 0.913898 trained in 21.4 seconds\n102_LightGBM_SelectedFeatures logloss 0.913898 trained in 21.43 seconds\n103_Xgboost_SelectedFeatures logloss 0.925216 trained in 44.41 seconds\n104_Xgboost_SelectedFeatures logloss 0.925216 trained in 43.88 seconds\n105_Xgboost logloss 0.92657 trained in 33.08 seconds\n106_Xgboost logloss 0.92657 trained in 33.05 seconds\n107_Xgboost logloss 0.927383 trained in 31.14 seconds\n108_Xgboost logloss 0.927383 trained in 30.75 seconds\n109_RandomForest logloss 0.936886 trained in 34.12 seconds\n110_RandomForest logloss 0.929509 trained in 33.98 seconds\n111_LightGBM logloss 0.934819 trained in 23.27 seconds\n112_ExtraTrees logloss 0.945128 trained in 29.91 seconds\n113_ExtraTrees logloss 0.937595 trained in 30.47 seconds\n114_RandomForest logloss 0.95299 trained in 33.67 seconds\n115_RandomForest logloss 0.945088 trained in 32.4 seconds\n116_RandomForest_SelectedFeatures logloss 0.943462 trained in 32.88 seconds\n117_RandomForest_SelectedFeatures logloss 0.935899 trained in 31.25 seconds\n118_ExtraTrees logloss 0.957263 trained in 33.67 seconds\n119_ExtraTrees logloss 0.946509 trained in 31.66 seconds\n120_NeuralNetwork_SelectedFeatures logloss 1.013915 trained in 25.81 seconds\n121_NeuralNetwork_SelectedFeatures logloss 0.955666 trained in 25.81 seconds\n122_NeuralNetwork_SelectedFeatures logloss 0.97975 trained in 26.07 seconds\n123_DecisionTree logloss 1.085933 trained in 24.58 seconds\n124_DecisionTree logloss 1.686881 trained in 24.78 seconds\n125_DecisionTree logloss 2.509618 trained in 24.66 seconds\n* Step boost_on_errors will try to check up to 1 model\n99_CatBoost_BoostOnErrors logloss 0.919416 trained in 26.81 seconds\n* Step ensemble will try to check up to 1 model\nEnsemble logloss 0.891175 trained in 73.53 seconds\nAutoML fit time: 3083.88 seconds\nAutoML best model: Ensemble\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"AutoML(mode='Compete')"},"metadata":{}}]},{"cell_type":"code","source":"X_test=pd.read_csv('/kaggle/input/the-data-alchemist-techweek-23/test.csv')\npredictions = a.predict(X_test)\npredictions\n","metadata":{"execution":{"iopub.status.busy":"2023-01-15T18:15:12.388284Z","iopub.execute_input":"2023-01-15T18:15:12.388702Z","iopub.status.idle":"2023-01-15T18:15:16.847777Z","shell.execute_reply.started":"2023-01-15T18:15:12.388669Z","shell.execute_reply":"2023-01-15T18:15:16.846683Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"array(['A', 'A', 'A', 'A', 'A', 'A', 'H', 'H', 'A', 'H', 'H', 'A', 'H',\n       'H', 'D', 'A', 'H', 'H', 'H', 'H', 'A', 'H', 'H', 'A', 'H', 'H',\n       'H', 'A', 'A', 'H', 'A', 'H', 'H', 'H', 'H', 'A', 'A', 'A', 'H',\n       'A', 'A', 'H', 'H', 'A', 'H', 'H', 'A', 'A', 'H', 'H', 'A', 'H',\n       'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'A', 'A', 'H', 'H',\n       'H', 'H', 'A', 'H', 'H', 'H', 'A', 'H', 'A', 'H', 'H', 'H', 'A',\n       'A', 'H', 'A', 'H', 'H', 'H', 'A', 'A', 'H', 'H', 'H', 'A', 'H',\n       'H', 'A', 'H', 'H', 'H', 'H', 'H', 'H', 'A', 'H', 'A', 'H', 'H',\n       'H', 'H', 'A', 'A', 'H', 'A', 'A', 'H', 'H', 'A'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"output = pd.DataFrame({'id': X_test.id,\n                       'result': predictions})\n","metadata":{"execution":{"iopub.status.busy":"2023-01-15T18:15:16.849352Z","iopub.execute_input":"2023-01-15T18:15:16.849674Z","iopub.status.idle":"2023-01-15T18:15:16.855174Z","shell.execute_reply.started":"2023-01-15T18:15:16.849647Z","shell.execute_reply":"2023-01-15T18:15:16.854234Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"output","metadata":{"execution":{"iopub.status.busy":"2023-01-15T18:15:16.856567Z","iopub.execute_input":"2023-01-15T18:15:16.856846Z","iopub.status.idle":"2023-01-15T18:15:16.877951Z","shell.execute_reply.started":"2023-01-15T18:15:16.856820Z","shell.execute_reply":"2023-01-15T18:15:16.876798Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"      id result\n0    336      A\n1    104      A\n2     40      A\n3    364      A\n4    234      A\n..   ...    ...\n109  102      A\n110  178      A\n111   76      H\n112  200      H\n113  251      A\n\n[114 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>result</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>336</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>104</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>40</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>364</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>234</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>109</th>\n      <td>102</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>110</th>\n      <td>178</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>111</th>\n      <td>76</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>112</th>\n      <td>200</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>113</th>\n      <td>251</td>\n      <td>A</td>\n    </tr>\n  </tbody>\n</table>\n<p>114 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"output.to_csv('submissionauto.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-15T18:15:16.879613Z","iopub.execute_input":"2023-01-15T18:15:16.880430Z","iopub.status.idle":"2023-01-15T18:15:16.886673Z","shell.execute_reply.started":"2023-01-15T18:15:16.880386Z","shell.execute_reply":"2023-01-15T18:15:16.885554Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}